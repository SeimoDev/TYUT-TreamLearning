# 朴素贝叶斯：

朴素贝叶斯是一种直接衡量标签和特征之间的概率关系的有监督算法，它既可以做回归也可以分类，不过多是用于分类之中。

朴素贝叶斯是一个不建模的算法。

**算法得出的结论，永远不是100%确定的，更多的是判断出了一种“样本的标签更可能是某类的可能性”，而非一种“确定”。**

每种算法使用不同的指标来衡量这种可能性。比如说，决策树使用的就是叶子节点上占比较多的标签所占的比例
（接口predict_proba调用），逻辑回归使用的是sigmoid函数压缩后的似然（接口predict_proba调用），而SVM
使用的是样本点到决策边界的距离（接口decision_function调用）。但这些指标的本质，其实都是一种“类概率”的
表示，我们可以通过归一化或sigmoid函数将这些指标压缩到0~1之间，让他们表示我们的模型对预测的结果究竟
有多大的把握（置信度）。

![](C:%5CUsers%5C%E9%93%B6%E6%99%97%5CPictures%5CSaved%20Pictures%5C51.png)

#### 高斯朴素贝叶斯分布：

sklearn.naive_bayes.GaussianNB (priors=None, var_smoothing=1e-09)

高斯朴素贝叶斯，通过假设 是服从高斯分布（也就是正态分布），来估计每个特征下每个类别上的条件概率。

![](C:%5CUsers%5C%E9%93%B6%E6%99%97%5CPictures%5CSaved%20Pictures%5C52.png)

高斯朴素贝叶斯以最大化 P(X|Y)为目标，来求解该式中的参数  和 。求解出参数后，带入一个 x的值，就能得到相应的概率取值.

* prior : 
    可输入任何类数组结构，形状为（n_classes，）.表示类的先验概率。如果指定，则不根据数据调整先验，如果不指定，则自行根据数据计算先验概率 

* var_smoothing :浮点数，可不填（默认值= 1e-9）,在估计方差时，为了追求估计的稳定性，将所有特征的方差中最大的方差以某个比例添加到估计的方差中。这个比例，由var_smoothing参数控制

#### 伯努利贝叶斯：
 ```sklearn.naive_bayes.BernoulliNB (alpha=1.0, binarize=0.0, fit_prior=True, class_prior=None)```

#### 多项式朴素贝叶斯：
```sklearn.naive_bayes.MultinomialNB (alpha=1.0, fit_prior=True, class_prior=None)```

#### 补集贝叶斯：
``` sklearn.naive_bayes.MultinomialNB (alpha=1.0, fit_prior=True, class_prior=None)```

### 概率类模型的评估指标：
sklearn.metrics.brier_score_loss
BS(y_true, y_prob, *, sample_weight=None, pos_label=None)

 * 布利尔指标：
 > 概率预测的准确程度被称为“校准程度”，是衡量算法预测出的概率和真实概率的差异的一种方式，在二分类中，最常用的指标叫做布里尔分数，它被计算为是概率预测相对于测试样本的均方误差

![](C:%5CUsers%5C%E9%93%B6%E6%99%97%5CPictures%5CSaved%20Pictures%5C53.png)

其中N是样本数量， 为朴素贝叶斯预测出的概率， 是样本所对应的真实结果，只能取到0或者1，如果事件发生则为1，如果不发生则为0。这个指标衡量了我们的概率距离真实标签结果的差异，其实看起来非常像是均方误差。

**布里尔分数的范围是从0到1，分数越高则贝叶斯的预测结果越差劲**

### 使用混淆矩阵来查看分类结果

![](C:%5CUsers%5C%E9%93%B6%E6%99%97%5CPictures%5CSaved%20Pictures%5C54.png)

* sklearn.metrics.confusion_matrix

混淆矩阵是二分类问题的多维衡量指标体系，在样本不平衡时及其有用。
少数类是正例，多数类是负例。
![](C:%5CUsers%5C%E9%93%B6%E6%99%97%5CPictures%5CSaved%20Pictures%5C55.png)

真实值在前面，预测值在后。对角线的11，00就是预测正确的。

#### 准确率：

橙色表示分母，绿色表示分子

![](C:%5CUsers%5C%E9%93%B6%E6%99%97%5CPictures%5CSaved%20Pictures%5C56.png)

**准确率就是所有预测正确的样本除以总样本，越接近1越好**

#### 精确率：

> 又叫查准率，表示所有被我们预测的样本中，真正的少数类所占的比例。
> ![](C:%5CUsers%5C%E9%93%B6%E6%99%97%5CPictures%5CSaved%20Pictures%5C57.png)

精确度形象的表示为，决策边界上方的所有点中，红色点所占的比例，红色比例越高，精确度越高。
![](C:%5CUsers%5C%E9%93%B6%E6%99%97%5CPictures%5CSaved%20Pictures%5C58.png)

`True =1,预测对的除以所有的
(y[y == clf.predict(x)]==1).sum()/(clf.predict(x)==1).sum()`

精确度是将多数类分错后所需付出的成本

#### 召回率：
> 所有样本真实为1的样本中，被我们预测为正确的样本的比例。
> 召回率可表示为，决策边界上方的所有红色点占全部样本中红色点的比例

![](C:%5CUsers%5C%E9%93%B6%E6%99%97%5CPictures%5CSaved%20Pictures%5C59.png)

召回率越高，代表我们尽量捕获出了越多的少数类，召回率越低，代表我们没有补货出足够的少数类。

`#predict为1 的点 / 全部为1的点的比例
(y[y == clf.predict(x)]==1).sum()/(y==1).sum()`





#### 实战代码

```python
#predict为1 的点 / 全部为1的点的比例
(y[y == clf.predict(x)]==1).sum()/(y==1).sum()

from sklearn.metrics import brier_score_loss as BS

import numpy as np
import matplotlib.pyplot as plt
from sklearn.naive_bayes import GaussianNB
from sklearn.datasets import load_digits
from sklearn.model_selection import train_test_split
digits = load_digits()
X, y = digits.data, digits.target
Xtrain,Xtest,Ytrain,Ytest = train_test_split(X,y
                        ,test_size=0.3,random_state=420)

#建模
gnb = GaussianNB().fit(Xtrain,Ytrain)
#查看分数
acc_score = gnb.score(Xtest,Ytest)
#查看预测结果
Y_pred = gnb.predict(Xtest)
#查看预测的概率结果
prob = gnb.predict_proba(Xtest)

prob.shape

#混淆矩阵和精确性可以帮助我们了解贝叶斯的分类结果
from sklearn.metrics import confusion_matrix as CM
CM(Ytest,Y_pred)

#使用布里尔系数进行评估
from sklearn.metrics import brier_score_loss
brier_score_loss(Ytest, prob[:,0], pos_label=0)
#我们的pos_label与prob中的索引一致，就可以查看这个类别
```



