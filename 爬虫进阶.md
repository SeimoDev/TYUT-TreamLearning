# 异步爬虫：

目的：在爬虫中使用异步实现高性能的数据的爬取

```python
#同步爬虫，单线程，get()很慢，是一个阻塞的方法
response=requests.get(url=url,headers=headers)
if response.status_code == 200:				#判断是否有响应
	return response.content
	
```

异步爬虫方式：

1. 多线程，多进程：可以为相关阻塞的操作单独开启线程或者进程，不会等。但是不能无限制的开启多线程

2. 线程池、进程池：可以降低系统对进程或者线程创建和销毁的一个频率，提升效率。但是池中线程数量有上限

   ```python
   from multiprocessing.dummy import Pool
   
   name_list=['aa','bb','cc','dd']
   def get_page(str):
   {
       print(str)
   }
   #实例化线程对象
   pool=Pool(4)	#四个对象
   pool.map(get_page,name_list)	#map(阻塞的方法，对象列表)
   ```

   

3. 单线程+异步协程：

   1. event_loop:事件循环，相当于无限循环，把函数注册到事件循环上，当满足某些条件时，函数就会被循环执行
   2. coroutine:协程对象，把协程的对象注册到事件循环中，它会被事件循环调用。我们可以使用async关键字来定义一个方法，这个方法在调用时不会立即执行，而是返回一个协程对象。
   3. task:任务，它是对协程对象的封装，包含了任务的各个状态。
   4. future:代表将来执行或者还没执行的任务，和task没有本质区别
   5. async:定义一个协程
   6. await:用来挂起阻塞的方法

```python
import asyncio


async def request(url):
    # 用async修饰的函数，调用后返回是一个协程对象
    print('请求的对象是', url)


c = request('www.baidu.com')

# #创建事件循环对象
# loop = asyncio.get_event_loop()
# #将协程对象注册到loop中，然后启动loop
# loop.run_until_complete(c)

# task的使用
loop = asyncio.get_event_loop()
# 基于loop创建一个task对象
task= loop.create_task(c)
print(task)
loop.run_until_complete(task)
print(task)
#future的使用
loop = asyncio.get_event_loop()
task= asyncio.ensure_future(c)
loop.run_until_complete(task)

# 多任务异步协程实现
urls = {
    'www.baidu.com',
    'www.sougou.com',
    'www.goubanjia.com',
}
stasks = []  # 存放任务列表
for url in urls:
    c = request(url)
    task = asyncio.ensure_future(c)
    stasks.append(task)
    # 需要将任务列表封装到wait中
    loop.run_until_complete(asyncio.wait(stasks))
    # 但是在异步协程中出现同步模块的代码，那么无法实现异步

async def requests(url):
    print('正在下载',url)
    # 改一下time.sleep(2)
    await asyncio.sleep(2)
```

# 模拟登录

## 验证码的识别：

1. 对网页发起request请求，拿到验证码的图片链接
2. 拿到链接之后，再对这个图片的链接发起request请求，拿到content二进制数据
3. 然后打开一个文件，将二进制数据write到这个文件里面
4. 第三方平台进行解码（传入图片文件路径，验证码类型）
5. 登录之后，找到login的数据包，拿到param参数列表，更改icode ，改为验证码识别的内容
6. 再次发送post请求，拿到page_text
7. 利用状态码，看是否是200，是200就成功了

登录成功之后，重新发起详情页的请求后，页面会重新回到登录页面，因为cookies的原因

### 自动处理cookies：

1.cookies值的来源来自哪里？来源上一次对网页发起请求后生成的

2.使用session对象：

​	1.可以进行请求的发送 

​	2.如果请求过程中产生了cookie，则该cookie会被自动储存，即携带在session对象中

#### 创建session对象

```python
#自动携带cookie，不用手动写cookies了
session = requests.Session()
response = session.get(url,headers,data)
```



### 失败常见原因

1.url错误

2.登陆后的参数列表错误，参数列表除了icode其余都要写成键值对的形式，**因为icode每次都会变化**



## 如何保存图片和HTML文件：

```python
#图片数据
with open('./code.jpg','wb') as fp:
	fp.write(img_data)
#HTML文件    
with open('./return.html','w',encoding = 'utf-8') as fp:
	fp.write(login_page_text)    
```

### 代理使用：

```python
#构建代理池
proxie = { 
        'http' : 'http://xx.xxx.xxx.xxx:xxxx',
        'http' : 'http://xxx.xx.xx.xxx:xxx',
        ....
    }  

response = request.get(url,headers,proxies={'http/https':'代理号'})
```



## 异步





## 协程

> 协程不是计算机提供，程序员是认为创造。
>
> 也叫微线程，是一种用户态内的上下文切换技术，简而言之，其实就是通过，一个线程实现**代码块相互切换**。

---

#### 协程的意义

> 在一个协程中如果遇到IO等待时间，线程不会等待，利用空闲的时候再去干的别的事。

实现协程的方法：

* greenlet :早期模块
* yield ：生成器
* asyncio装饰器
* async，await关键字

### greenlet

```python
def func1():
	print(1)     #第1步：输出1
	gr2.switch() #第2步：切换到func2
	print(2)   #第5步 输出2
	gr2.switch() #第6步 切换func2
	
def func2():
	print(3)  #第3步 输出3
	gr1.switch() #第4步 切换func1
	print(4) #第7步 输出4
    
gr1 = greenlet(func1)
gr2 = greenlet(func2)

gr1.switch(func1) 
```

### yield

```python
def func1():
    yield 1
    yield from func2() #跳到func2
    yield 2
    
def func2():
    yield 3
    yield from func1()
    yield 4
    
f1 = func1()
from item in f1:
    print(item)
```

### asyncio

> 遇到IO阻塞就自动切换代码块执行，遇到耗时的操作要等待的时候，就立即切换下一个代码块，加快速度
>
> ---
>
> 协程函数：`asyncio def 函数名`
>
> 协程对象: 执行协程函数产生的协程对象
>
> ```python
> asyncio def func():
>     print(...)
>     
> result = func()
> asyncio.run(result)
> ```
>
> 

| asyncio                      | 描述                   |
| ---------------------------- | ---------------------- |
| get_event_loop()             | 开启事件循环           |
| run_until_complete(task列表) | 执行任务               |
| await()                      | 等待事件结束，返回结果 |
| run()                        | 运行                   |
| ensure_future()              | 创建future对象         |

### 理解性代码：

```python
import asyncio

async def func1(): #必须带上关键字async
    print(3)
    await asyncio.sleep()  #模拟耗时操作，自动切换
    print(2)
    
    
async def func2(): 
    print(3)
    await asyncio.sleep()
    print(4)
    
 tasks = [
     asyncio.ensure_future(func1())
     asyncio.ensure_future(func2())
 ]

loop = asyncio.get_event_loop()
loop.run_until_complete(asyncio.wait(tasks))
```

### 事件循环：

理解为一个死循环

1.去检测任务列表，

2.如果任务可执行，就去执行，

3.如果不可执行，就忽略跳过，

4.如果有任务执行完成，就从任务列表中移除

代码操作：

```python
import asyncio

#生成一个事件循环
loop = asyncio.get_event_loop()

#将任务循环放到任务列表
loop.run_until_complete(任务)
```

### await

> await + 可等待对象（协程对象、Future对象、Task对象）

```python
#单个协程对象
async def func():
	print('..')
	result = await asyncio.sleep(2)  #等待这个io结束,并返回结果
	print(result)
	
asyncio.run(func())
```

```python
#多个协程对象
async def others():
    print('start')
    await asyncio.sleep(2)
    print('end')
	return 2
    
    
async def func1():
	print('..')
	result1 = await others() #接收返回的2
	print(result1)
    
async def func2():
	print('..')
    result1 = await others() #遇到IO阻塞，会切换到其他的协程但是不会执行result2
	print(result1)
	result2 = await others() #接收返回的2
	print(result2)	

asyncio.run(func())
```

### Task对象

> 在事件循环中添加多个任务
>
> Task用于并发调度协程，通过asyncio.create_task(协程对象)的方式创建Task对象，这样可以让协程加入事件循环中等待被调度执行。除此之外，太可以用低级一点的loop.create_task ()或者 ensure_future() 函数，本质上是一样的。

示例代码1：

```python
async def others():
    print('start')
    await asyncio.sleep(2)
    print('end')
	return 2

async def main():
    print('main开始')
    
    task1 = asyncio.create_task(func())
    
    #这里特别解释一下，task1中在执行others函数中 await的sleep的操作时遇到阻塞会自动切换到task2去执行，所以输出第一个start然后接着输出第二个start
    
    task2 = asyncio.create_task(func())
    
    ret1 = await task1
    ret2 = await task2
    
    
asyncio.run(main())
```

实例代码2：

```python
async def others():
    print('start')
    await asyncio.sleep(2)
    print('end')
	return 2

async def main():
    print('main开始')
    
    task_list =[
        asyncio.create_task(func(),name = '设置task的名字'),
        asyncio.create_task(func())
    ]
    print('main结束')
    
    done,pending = await asyncio.wait(task_list，timeout=2)  
    
    #等待任务列表中的任务全部结束
    #done是已完成的任务的返回值的列表
    #pending是超过timeout时间问完成的任务列表
    
asyncio.run(main())

#另一种写法：
task_list =[
        func(),
        func()，
    ]
#这里会内部自动创建任务，所以列表中就不用创建任务
asyncio.run(asyncio.wait(task_list))
```

### asyncio.Future对象

> 基于协程，Task继承Future，Task对象内部await结果处理基于Future对象

```python
async def main():
    #创建当前时间循环
	loop = asyncio.get_running_loop()
    
    #创建future对象的任务
    fut = loop.create_future()
    
    #等待任务循环（Future对象），没有结果则会一直等下去
    await fut
    
    
asyncio.run(main())
```

实例代码：

```python
async def func(fut):
    await asyncio.sleep(2)
    fut.func('666')

async def main():
    #创建当前时间循环
	loop = asyncio.get_running_loop()
	fut = loop.create_future()
	
    #创建任务，绑定func任务
	await loop.create_task( func(fut) )
    
    data = awiat fut
    print(data)
```

### concurrent.futures.Future对象：

> 使用线程池、进程池实现异步操作时用到的对象

```python
from concurrent.futures import Future
from concurrent.futures.thread import ThreadPoolExcutor
from concurrent.futures.process import ProcessExecutor

def func(values):
    time.sleep(1)
    print(values)
    
#创建线程池
pool = ThreadPoolExecutor(max_workers = 5)
#创建线程池
pool = ProcessPoolExecutor(max_workers = 5)

for i in range(10):
    fut = pool.submit(func , i )
    #创建10个线程，但线程池容量为5
    print(fut)
```



```python
import time
import asyncio
import concurrent.futures

def func1():
    time.sleep(2)
    return "bb"

async def main():
    loop = asyncio.get_running_loop()
    
    #首先，内部调用THreadPoolExecute方法去线程池中执行func函数，并返回一个concurrent.futures.Future对象
    #然后，调用asyncio.wrap_future对象将concurrent.futures.Future对象包装成asyncio.Future对象，因为concurrent.futures.Future对象不支持await方法，所以需要包装
    fut = loop.run_in_executor(None, func1)
    result = await fut
    print('default thread pool' ,result)
    
    #使用线程池
    with concurrent.futures.ThreadPoolExecutor() as pool:
        result = await loop.run_in_execute(pool,func1)
    #使用进程池   
    with concurrent.futures.ProcessPoolExecute() as pool:
        result = await loop.run_in_execute(pool,func1)
        
 asyncio.run(main())
```

实战案例：

![1636385289648](C:%5CUsers%5C%E9%93%B6%E6%99%97%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1636385289648.png)

爬虫内部有三个线程，下载一个图片的同时会执行其他的线程，即下载另一张图片



#### 异步上下文管理器

> 自动打开和关闭协程函数

> 定义_ _aenyer_ _()和_ _ _aexit_ _ _()方法对async with 语句中的环境进行控制

```python
class AsyncManager:
    def __init__(self):
        self.conn = conn
        
    #第2步：执行函数
    async def do_something(self):
        return 666
    
    #第1步：先执行这里
    async def __aenter__(self):
        #异步连接数据库
        self.conn = await asyncio.sleep(1)
        return self
    
    async def __aexit__(self,exc_type,exc,tb):
        await asyncio.sleep(1)

 	async def func():        
        asynci with AsyncManager() as f:
            result = await f.do_something()
            print(result)
 asyncio.run(func())
```

#### 异步连接Mysql

```python
pip install aiomysql
```

```python
import asyncio
import aiomysql

async def execute():
    #连接数据库,先连接'47.93.41.197',遇到阻塞就连接'23.23.67.346'
    conn = await 		    aiomysql.connect(host=host,port=3306,user='root',password=' '，db="mysql")
    
    #网络IO操作，遇到阻塞会自动切换任务
    cur = await conn.cursor()
    
    #网络IO操作，遇到阻塞会自动切换任务
    await cur.execute("SELECT HOST ,USER FROM user")
    await cur.execute('select* from exp ...')
    #网络IO操作，遇到阻塞会自动切换任务
    result = await cur.fetchall()
    print(result)
    
    #网络IO操作，遇到阻塞会自动切换任务
    await cur.close()
    conn.close()
    print("结束")
task_list = [
    execute('47.93.41.197',"root12345"),
    execute('23.23.67.346',"root12345")
]    
  
```

#### 异步爬虫

```python
pip install aiohttp
```

![1636416125977](C:%5CUsers%5C%E9%93%B6%E6%99%97%5CAppData%5CRoaming%5CTypora%5Ctypora-user-images%5C1636416125977.png)

